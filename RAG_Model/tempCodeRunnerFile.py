import os
import pandas as pd
import google.generativeai as genai
import chromadb
import logging
from dotenv import load_dotenv

# ‚úÖ **Load API Key from Environment Variable**
load_dotenv()
API_KEY = os.getenv('GOOGLE_API_KEY')

if not API_KEY:
    raise ValueError("‚ùå GOOGLE_API_KEY not found in environment variables!")

genai.configure(api_key=API_KEY)

# ‚úÖ **Initialize ChromaDB**
chroma_client = chromadb.PersistentClient(path="./chroma_db")
HatespeechDB = chroma_client.get_or_create_collection(
    name="hate_speech_db",
    metadata={"hnsw:space": "cosine"}
)

# ‚úÖ **Load CSV Data**
csv_file = "Dataset/hate_speech_text_updated.csv"  # Adjust path as needed

if not os.path.exists(csv_file):
    raise FileNotFoundError(f"‚ùå CSV file not found at: {csv_file}")

df = pd.read_csv(csv_file)
df.dropna(subset=["Text"], inplace=True)
print(f"‚úÖ Loaded {len(df)} records from CSV!")

# ‚úÖ **Configure Embeddings**
embedding_model = "models/text-embedding-004"
logging.getLogger("chromadb").setLevel(logging.ERROR)

# ‚úÖ **Generate & Store Embeddings in ChromaDB**
if HatespeechDB.count() == 0:
    print("‚ö° Generating and storing embeddings for the first time...")

    for index, row in df.iterrows():
        embedding_response = genai.embed_content(
            model=embedding_model, 
            content=row["Text"]
        )
        embedding = embedding_response["embedding"]

        if len(embedding) != 768:
            raise ValueError(f"‚ùå Expected embedding dimension 768, but got {len(embedding)}")

        HatespeechDB.add(
            ids=[str(index)],
            documents=[row["Text"]],
            embeddings=[embedding],  # Ensure it's a list
            metadatas=[{"label": row["Label"], "category": row["Category"]}]
        )

    print("‚úÖ Embeddings stored in ChromaDB!")
else:
    print("‚úÖ Embeddings already exist in ChromaDB, skipping computation.")

# üöÄ **RAG Function: Retrieve & Classify Text**
def classify_text(input_text):
    """Retrieve relevant texts from ChromaDB and classify input using Gemini."""
    
    # ‚úÖ **Generate Embedding for Query**
    embedding_response = genai.embed_content(model=embedding_model, content=input_text)
    input_embedding = embedding_response["embedding"]

    if len(input_embedding) != 768:
        raise ValueError(f"‚ùå Expected query embedding dimension 768, but got {len(input_embedding)}")

    print(f"üîç Query Embedding Dimension: {len(input_embedding)}")

    # ‚úÖ **Retrieve Similar Texts from ChromaDB**
    results = HatespeechDB.query(
        query_embeddings=[input_embedding],  # Use query_embeddings, not query_texts
        n_results=2
    )

    retrieved_texts = results["documents"][0] if results["documents"] else []
    print(f"üîç Retrieved Texts: {retrieved_texts}")
    print(f"Input Text {input_text}")
    
    # ‚úÖ **Prompt for Classification**
    prompt = f"""
    Given the retrieved examples: {retrieved_texts}
    Classify the following text as 'Hate Speech', 'Moderate', or 'Safe':  
    "{input_text}"
    Respond with only one label.
    """

    model = genai.GenerativeModel("gemini-1.5-pro")
    response = model.generate_content(prompt)
    
    return response.text.strip()